Wedding Photo ‚ÄúPick-a-Face‚Äù System ‚Äî DynamoDB + Incremental Rebuild (Option A2)

This doc is your future vibe-coding blueprint: what you‚Äôre building, why it‚Äôs cheap, and exactly how the pieces talk to each other.

‚∏ª

1. Goal

A wedding website where guests can:
	‚Ä¢	Upload photos/videos
	‚Ä¢	See a People page with face clusters (tap a face cluster to claim ‚Äúthis is me‚Äù)
	‚Ä¢	Download all photos containing that person

Constraints:
	‚Ä¢	Minimum deployment cost
	‚Ä¢	Low concurrency (small crowd)
	‚Ä¢	Prefer Python for backend logic
	‚Ä¢	Avoid heavy web dev (frontend should be dumb)

‚∏ª

2. High-Level Architecture

Frontend
	‚Ä¢	GitHub Pages (static site)
	‚Ä¢	Upload UI
	‚Ä¢	People page UI (clusters + photo list)
	‚Ä¢	Talks to backend via HTTPS (API Gateway)

Backend (serverless)
	‚Ä¢	S3: raw media + face thumbnails
	‚Ä¢	API Gateway: REST endpoints
	‚Ä¢	Lambda (Python):
	‚Ä¢	Generate presigned S3 URLs
	‚Ä¢	Process uploads (detect/index faces, crop thumbnails)
	‚Ä¢	Incremental cluster rebuild job
	‚Ä¢	Rekognition:
	‚Ä¢	IndexFaces into a Collection
	‚Ä¢	SearchFaces for similarity graph edges
	‚Ä¢	DynamoDB: metadata + cluster state (fast queries)

Videos: store/upload/download via S3; face clustering applies to photos (MVP). Keep video face analysis as phase 2.

‚∏ª

3. Core Idea: Incremental Rebuild (Option A2)

We avoid ‚Äúlive merging complexity‚Äù but also avoid stale indexes by doing:
	‚Ä¢	Continuous indexing on every photo upload ‚Üí faces are immediately stored (FaceOccurrence)
	‚Ä¢	A scheduled Incremental Rebuild (every 2‚Äì5 minutes during event)
	‚Ä¢	Processes only new faces since last checkpoint
	‚Ä¢	Assigns them to existing clusters (or creates new clusters)
	‚Ä¢	Updates summary counts + ClusterPhoto mapping
	‚Ä¢	A less frequent Full Rebuild (manual or hourly)
	‚Ä¢	Handles merges/splits for better quality (optional but recommended)

This makes the People page feel near-real-time without building a gnarly streaming cluster merger.

‚∏ª

4. Data Model (DynamoDB)

4.1 Photo table

PK: photoId (UUID)

Attributes:
	‚Ä¢	s3KeyRaw
	‚Ä¢	uploadedAt
	‚Ä¢	status: RAW | INDEXED | FAILED
	‚Ä¢	faceCount
	‚Ä¢	optional: uploaderTag, fileType, etag

Purpose:
	‚Ä¢	Map photoId ‚Üí S3 key quickly
	‚Ä¢	Debug/retry

‚∏ª

4.2 FaceOccurrence table

Represents ‚Äúface X appears in photo Y‚Äù.

PK: faceId (Rekognition FaceId)
SK: photoId

Attributes:
	‚Ä¢	thumbS3Key (e.g., faces/thumbs/{faceId}.jpg)
	‚Ä¢	bbox
	‚Ä¢	confidence
	‚Ä¢	indexedAt (ISO time)

GSI1 (reverse lookup):
	‚Ä¢	GSI1PK = photoId
	‚Ä¢	GSI1SK = faceId

Purpose:
	‚Ä¢	Find all photos for a face (PK query)
	‚Ä¢	Find all faces in a photo (GSI1 query)
	‚Ä¢	Provide indexedAt for incremental rebuild (via scan/GSI strategy below)

‚∏ª

4.3 Cluster table

PK: clusterId

Attributes:
	‚Ä¢	repFaceId
	‚Ä¢	repThumbS3Key
	‚Ä¢	memberCount
	‚Ä¢	photoCount
	‚Ä¢	updatedAt
	‚Ä¢	optional: canonicalClusterId (used if you later implement merges/redirects)

Purpose:
	‚Ä¢	Cheap GET /clusters (scan is small ~10‚Äì50 items)

‚∏ª

4.4 ClusterMember table

PK: clusterId
SK: faceId

GSI1 (face ‚Üí cluster):
	‚Ä¢	GSI1PK = faceId
	‚Ä¢	GSI1SK = clusterId

Purpose:
	‚Ä¢	For a new face, find which cluster(s) its matched faces belong to.

‚∏ª

4.5 ClusterPhoto table (recommended)

PK: clusterId
SK: photoId

Attributes:
	‚Ä¢	bestFaceId (optional; face in that photo to highlight)
	‚Ä¢	addedAt

Purpose:
	‚Ä¢	Clicking a cluster should be a single DynamoDB Query.

‚∏ª

4.6 JobState table (or a single item)

PK: jobName (e.g., "incremental-cluster-rebuild")

Attributes:
	‚Ä¢	lastProcessedAt (checkpoint)
	‚Ä¢	lastRunAt
	‚Ä¢	status, stats

Purpose:
	‚Ä¢	Avoid reprocessing everything.

‚∏ª

5. S3 Layout
	‚Ä¢	Raw uploads:
	‚Ä¢	uploads/raw/{photoId}.jpg
	‚Ä¢	uploads/raw/{photoId}.heic (optional)
	‚Ä¢	uploads/raw/{videoId}.mp4
	‚Ä¢	Face thumbnails (small):
	‚Ä¢	faces/thumbs/{faceId}.jpg

Keep bucket private. Only use presigned URLs.

‚∏ª

6. Processing Pipeline

6.1 Upload flow (client)
	1.	Client calls GET /presign-upload?type=image/jpeg&ext=jpg
	2.	Backend returns photoId + presigned PUT URL + S3 key
	3.	Client uploads directly to S3 using PUT
	4.	Client calls POST /finalize-upload with photoId (optional but recommended)
	‚Ä¢	This avoids relying purely on S3 events for correctness

‚∏ª

6.2 Indexing flow (Lambda, Python)

Triggered by either:
	‚Ä¢	S3 ObjectCreated event on uploads/raw/
	‚Ä¢	or POST /finalize-upload (you can do both, but ensure idempotency)

Steps:
	1.	Write/Update Photo(photoId) ‚Üí status=RAW
	2.	Call Rekognition IndexFaces into Collection
	3.	For each detected face:
	‚Ä¢	Crop thumbnail and write faces/thumbs/{faceId}.jpg to S3
	‚Ä¢	Put item into FaceOccurrence(faceId, photoId) including indexedAt
	4.	Update Photo ‚Üí status=INDEXED, faceCount=N

‚∏ª

7. Incremental Rebuild Job (the heart)

7.1 Scheduling
	‚Ä¢	During wedding window: every 2‚Äì5 minutes
	‚Ä¢	After: hourly or manual
Use EventBridge schedule to invoke incremental_rebuild_lambda.

‚∏ª

7.2 How to get ‚Äúnew faces since checkpoint‚Äù

You need an efficient way to list new FaceIds since lastProcessedAt.

Two practical approaches:

A) Dedicated FaceIngest table (cleanest)
	‚Ä¢	On every IndexFaces, write:
	‚Ä¢	FaceIngest with PK=dayBucket (e.g. 2026-01-15), SK=indexedAt#faceId
	‚Ä¢	Then incremental job queries by day bucket + range.

B) Use FaceOccurrence + scan (acceptable at wedding scale)
	‚Ä¢	If total face count is small (few thousand), a scan with filter on indexedAt > lastProcessedAt is fine.
	‚Ä¢	Cheapest to implement, but not ‚Äúinfinite scale‚Äù.

Given your scale, B is fine; A is nicer if you want it clean.

‚∏ª

7.3 Assignment logic (incremental)

For each new faceId:
	1.	Find similar faces:
	‚Ä¢	Rekognition SearchFaces (collection) using faceId
	‚Ä¢	Keep matches above threshold (e.g., 90+; tune later)
	2.	For each matched mFaceId, find its cluster:
	‚Ä¢	Query ClusterMember GSI1 where faceId = mFaceId
	‚Ä¢	Collect candidate clusterIds
	3.	Choose target cluster:
	‚Ä¢	If no candidates ‚Üí create new clusterId
	‚Ä¢	If one candidate ‚Üí use it
	‚Ä¢	If multiple candidates:
	‚Ä¢	Incremental job chooses one canonical cluster (e.g., smallest clusterId)
	‚Ä¢	Add faceId to canonical cluster
	‚Ä¢	Record ‚ÄúmergeNeeded‚Äù flag somewhere (JobState / Cluster table) for later Full Rebuild
	‚Ä¢	(This keeps incremental job simple and stable)
	4.	Update DynamoDB:
	‚Ä¢	Put ClusterMember(clusterId, faceId)
	‚Ä¢	Update Cluster.memberCount += 1
	‚Ä¢	Choose/update Cluster.repFaceId if needed (optional heuristic below)
	5.	Add photos to ClusterPhoto:
	‚Ä¢	Query FaceOccurrence for this faceId ‚Üí yields photoIds
	‚Ä¢	For each photoId: Put ClusterPhoto(clusterId, photoId) (idempotent upsert)
	‚Ä¢	Update Cluster.photoCount (approx ok; or compute later)
	6.	Update checkpoint:
	‚Ä¢	JobState.lastProcessedAt = max(indexedAt processed)

‚∏ª

7.4 Representative thumbnail heuristic

Keep it simple:
	‚Ä¢	First face in cluster becomes representative
	‚Ä¢	Or choose the face with highest confidence / largest bbox area
Store:
	‚Ä¢	Cluster.repFaceId, Cluster.repThumbS3Key

‚∏ª

8. API Endpoints

Public endpoints
	‚Ä¢	GET /presign-upload
	‚Ä¢	returns {id, putUrl, s3Key}
	‚Ä¢	POST /finalize-upload
	‚Ä¢	body {photoId} (optional but recommended)
	‚Ä¢	GET /clusters
	‚Ä¢	returns clusters with presigned thumb URLs
	‚Ä¢	GET /clusters/{clusterId}/photos
	‚Ä¢	returns list of photos (presigned GET URLs)

Admin endpoints (protected by a secret or IAM)
	‚Ä¢	POST /rebuild/incremental (mostly for testing; scheduled normally)
	‚Ä¢	POST /rebuild/full (optional, better clustering quality)
	‚Ä¢	GET /admin/stats (optional)

‚∏ª

9. Freshness Guarantees

With incremental rebuild every 2‚Äì5 minutes:
	‚Ä¢	New faces appear in People page typically within a few minutes
	‚Ä¢	No heavy S3 index files
	‚Ä¢	Reads are simple and fast:
	‚Ä¢	GET /clusters ‚Üí scan small Cluster table
	‚Ä¢	click cluster ‚Üí query ClusterPhoto

Staleness is controlled by schedule, not by ‚Äúindex file drift‚Äù.

‚∏ª

10. Security Model
	‚Ä¢	S3 bucket private
	‚Ä¢	Only allow uploads via presigned URLs (prefix restricted)
	‚Ä¢	API protected by:
	‚Ä¢	wedding passcode (simple) + rate limiting
	‚Ä¢	optionally CloudFront + WAF later (probably unnecessary)
	‚Ä¢	Separate admin secret for rebuild triggers

‚∏ª

11. Cost Control Knobs
	‚Ä¢	Thumbnail size small (e.g., 160√ó160 JPEG)
	‚Ä¢	EventBridge schedule only during wedding window
	‚Ä¢	DynamoDB on-demand (tiny usage)
	‚Ä¢	S3 lifecycle: delete after N days (e.g., 120)
	‚Ä¢	Cap file sizes + count per upload batch

‚∏ª

12. ‚ÄúFull Rebuild‚Äù (optional but recommended)

Run occasionally to improve cluster quality and handle merges properly:
	‚Ä¢	Recompute clustering from all faces (union-find over Rekognition similarity)
	‚Ä¢	Rewrite Cluster, ClusterMember, ClusterPhoto from scratch
	‚Ä¢	This can be manual (‚ÄúAdmin button‚Äù) after the wedding

‚∏ª

13. Minimal Implementation Checklist
	1.	Create S3 bucket + CORS for uploads
	2.	Create Rekognition Collection
	3.	Create DynamoDB tables: Photo, FaceOccurrence, Cluster, ClusterMember, ClusterPhoto, JobState
	4.	Deploy Lambdas:
	‚Ä¢	presign_upload
	‚Ä¢	finalize_or_s3_event_processor (index faces + thumbs + write FaceOccurrence)
	‚Ä¢	incremental_rebuild
	5.	Create API Gateway routes
	6.	Create GitHub Pages UI:
	‚Ä¢	upload page
	‚Ä¢	People page (clusters + click ‚Üí photos)
	7.	Set EventBridge schedule during wedding window

‚∏ª

14. Notes for Future You (vibe coding warnings üòÑ)
	‚Ä¢	Idempotency matters: S3 events can duplicate; your writes should be safe to replay.
	‚Ä¢	Keep thresholds configurable (env var): similarity threshold strongly affects clustering.
	‚Ä¢	If incremental job starts accumulating ‚ÄúmergeNeeded‚Äù flags, run full rebuild.
	‚Ä¢	Don‚Äôt over-optimize early; wedding scale is forgiving.

‚∏ª

If you want, I can also draft the exact DynamoDB item shapes (example JSON records) and the incremental rebuild pseudo-code in Python (structured for Lambda), so you can straight-up implement it with minimal thinking.
